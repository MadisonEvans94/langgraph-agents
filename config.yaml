llm_configs:
  openai:
    default_llm:
      api_key: null # or null, read from env
      model: "gpt-3.5-turbo" # param name for ChatOpenAI
      temperature: 0.8
      max_tokens: 512
      top_p: 0.9
      # Any other openai-specific fields...
    alternate_llm:
      api_key: null
      model: "gpt-4o"
      temperature: 0.7
      max_tokens: 512
      top_p: 1.0
      # ...
  vllm:
    default_llm:
      api_key: null # or read from env
      base_url: "http://vllm-downstream:4882/v1"
      model_id: "meta-llama/Llama-3.1-8B-Instruct"
      max_new_tokens: 512
      temperature: 1.0
      top_p: 1.0
      repetition_penalty: 1.0
    alternate_llm:
      api_key: null
      base_url: "http://vllm-downstream-2:4882/v1"
      model_id: "mistralai/Mixtral-8x7B-v0.1"
      max_new_tokens: 512
      temperature: 1.0
      top_p: 1.0
      repetition_penalty: 1.0
